{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea082eb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b66a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.path.abspath(__file__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1198a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TF_AUTOTUNE\"] = \"1\"\n",
    "tf.keras.backend.set_floatx('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a53ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autotuning\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(BASE_DIR, 'dataset/train.tsv')\n",
    "test_path = os.path.join(BASE_DIR, 'dataset/test.tsv')\n",
    "validation_path = os.path.join(BASE_DIR, 'dataset/validation.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59efd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_labels = ['row', 'json_ids', 'label', 'statement', 'subject', 'speaker', 'job_title', 'state', 'affiliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'lies_counts', 'context', 'justification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c87785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Frames \n",
    "train = pd.read_csv(train_path, sep=\"\\t\", header=None, names=column_labels)\n",
    "test = pd.read_csv(test_path, sep=\"\\t\", header=None, names=column_labels)\n",
    "valid = pd.read_csv(validation_path, sep=\"\\t\", header=None, names=column_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab57d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill nan (empty boxes) with 0\n",
    "train = train.fillna('None')\n",
    "test = test.fillna('None')\n",
    "val = valid.fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94efce03",
   "metadata": {},
   "source": [
    "Mapping to binary classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85661522",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train['label']\n",
    "label_mapping = {label: idx for idx, label in enumerate(labels.unique())}\n",
    "print('label mapping', label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac771165",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label_encoded'] = np.where(np.isin(labels, ['mostly-true', 'true']), 1, 0)   # Mapping True as 1 and lies as 0\n",
    "val['label_encoded'] = np.where(np.isin(val['label'], ['mostly-true', 'true']), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c3a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5b64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['label_encoded'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9d248",
   "metadata": {},
   "source": [
    "train_one_hot_labels = to_categorical(train['label_encoded'], num_classes=num_of_classes)\n",
    "val_one_hot_labels = to_categorical(val['label_encoded'], num_classes=num_of_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b232da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'experts_wiki_books'\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "vocab_size = 10000  \n",
    "embedding_dim = 32  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe05fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom embedding layer\n",
    "custom_embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664cc2eb",
   "metadata": {},
   "source": [
    "metadata_columns = ['subjects', 'speakers', 'jobs', 'states', 'affiliations', 'contexts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737402ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only using statement data at first\n",
    "# Tokenize the statement data\n",
    "train_encoded_statement_data = tokenizer(\n",
    "    train['statement'].to_list(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e26c32b",
   "metadata": {},
   "source": [
    "train_labels = train['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6dca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_encoded_statement_data = tokenizer(\n",
    "    val['statement'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='tf'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49fd42",
   "metadata": {},
   "source": [
    "val_labels = val['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5347cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow dataset for training\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'input_ids': train_encoded_statement_data['input_ids'], \n",
    "        'attention_mask': train_encoded_statement_data['attention_mask']\n",
    "    }, \n",
    "    train['label_encoded'] ))  # using one-hot encoded labels when CategoricalCrossEntropy used, \n",
    "                            # and when using SparseCrossEntropy use train['label_encoded'] which is int rep for labels : 0, 1, 2 ..5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb990b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'input_ids': val_encoded_statement_data['input_ids'], \n",
    "        'attention_mask': val_encoded_statement_data['attention_mask']\n",
    "    },\n",
    "    val['label_encoded'] ))  # using one-hot encoded labels when CategoricalCrossEntropy used, \n",
    "                            # and when using SparseCrossEntropy use train['label_encoded'] which is int rep for labels : 0, 1, 2 ..5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa1b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limiting the dataset\n",
    "limit = 100  \n",
    "limited_train_dataset = train_dataset.take(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f11cf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df7d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 4\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ec3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new model with the BERT base and the custom output layer\n",
    "input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='attention_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a dense layer for the output \n",
    "# dense_layer = tf.keras.layers.Dense(num_of_classes, activation='softmax', name='dense_output')\n",
    "bert_output = model([input_ids, attention_mask])\n",
    "cls_token = bert_output.logits\n",
    "positive_class_logits = cls_token[:, 1]  # Extract logits for the positive class \n",
    "positive_class_logits = tf.expand_dims(positive_class_logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c887e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer = tf.keras.layers.Dense(1, activation='sigmoid', name='dense_output')\n",
    "output = dense_layer(positive_class_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tf.keras.layers.Dense(1, activation='sigmoid')(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff348582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final model\n",
    "custom_model = tf.keras.Model(inputs=model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc4f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "            loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18653174",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27642ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(BASE_DIR, 'model_checkpoint'),  # Specify the path to save the checkpoint\n",
    "    save_best_only=True,  # Save only the best model based on the validation loss\n",
    "    monitor='val_loss',  # Monitor the validation loss\n",
    "    mode='min',  # Mode can be 'min' or 'max' depending on the monitored metric\n",
    "    verbose=1  # Show progress while saving\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d10df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start training')\n",
    "history = custom_model.fit(\n",
    "    limited_train_dataset.shuffle(100).batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE),\n",
    "    verbose=1,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011fee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model if needed\n",
    "custom_model.save_pretrained(os.path.join(BASE_DIR, 'trained_model'))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
