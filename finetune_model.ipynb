{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45732dc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification, DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "from common import BASE_DIR, train_dataset, val_dataset, num_epochs, batch_size\n",
    "import os\n",
    "from tensorflow.keras import mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c61f319",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BERT Preprocess Model\n",
    "'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "\"\"\"\n",
    "bert_encoders = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "}\n",
    "mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ea5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_preprocess = {\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c51cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'experts_wiki_books'\n",
    "model_name = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549ec17e",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b205e",
   "metadata": {},
   "source": [
    "print(model)\n",
    "bert_preprocess_model = hub.KerasLayer(preprocess)\n",
    "bert_model = hub.KerasLayer(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b157b8",
   "metadata": {},
   "source": [
    "text_test = [\"I'm the only person on this stage who has worked actively just last year passing, along with Russ Feingold, some of the toughest ethics reform since Watergate.\tethics\tbarack-obama\tPresident\tIllinois\tdemocrat\t70.0\t71.0\t160.0\t163.0\t9.0\ta Democratic debate in Philadelphia, Pa.\tHowever, it was not that bill, but another one, sponsored by Majority Leader Harry Reid and introduced five days earlier on Jan.  4, 2007 that eventually became law. Obama was not a cosponsor\"]\n",
    "text_preprocessed = bert_preprocess_model(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf2afd",
   "metadata": {},
   "source": [
    "bert_results = bert_model(text_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396edbe9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class BERT_classifier(object):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # Using Expert Preprocessed BERT model\n",
    "        self.encoder = bert_encoders['distilbert-base-uncased']\n",
    "        self.preprocess = bert_preprocess['distilbert-base-uncased']\n",
    "        \n",
    "    def build_classifier_model(self):\n",
    "        text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "        preprocessing_layer = hub.KerasLayer(self.preprocess, name='preprocessing')\n",
    "        encoder_inputs = preprocessing_layer(text_input)\n",
    "        encoder = hub.KerasLayer(self.encoder, trainable=True, name='BERT_encoder')\n",
    "        outputs = encoder(encoder_inputs)\n",
    "        net = outputs['pooled_output']\n",
    "        net = tf.keras.layers.Dropout(0.1)(net)\n",
    "        net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "        return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a17df",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "classifier_model = BERT_classifier().build_classifier_model()\n",
    "# bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "# print(tf.sigmoid(bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d3bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = classifier_model.fit(\n",
    "    train_dataset.shuffle(10000).batch(batch_size),\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_dataset.batch(batch_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070c449e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "classifier_model.save_pretrained(os.path.join(BASE_DIR, 'trained_model'))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
